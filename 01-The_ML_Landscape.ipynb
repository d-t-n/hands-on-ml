{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1: The Machine Learning Landscape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Machine Learning?\n",
    "\n",
    "Machine Learning is the science (and art) of programming computers so they can\n",
    "learn from data.\n",
    "\n",
    "Here is a slightly more general definition:\n",
    "> [Machine Learning is the] field of study that gives computers the ability to learn\n",
    "without being explicitly programmed. — Arthur Samuel, 1959\n",
    "\n",
    "And a more engineering-oriented one:\n",
    "> A computer program is said to learn from experience E with respect to some task T\n",
    "and some performance measure P, if its performance on T, as measured by P, improves\n",
    "with experience E. — Tom Mitchell, 1997"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why use Machine Learning?\n",
    "\n",
    "Machine Learning excels in solving complex problems that are challenging for traditional approaches or lack known algorithms. For instance, speech recognition algorithms can learn to distinguish words by analyzing large amounts of example recordings, overcoming the limitations of simplistic rule-based techniques.\n",
    "\n",
    "Machine Learning can also provide insights into complex problems and large datasets through data mining. Algorithms can be inspected to uncover correlations, trends, and patterns that may not be immediately apparent, leading to a better understanding of the problem at hand.\n",
    "\n",
    "In summary, Machine Learning is beneficial for problems requiring extensive fine-tuning or rule-based approaches, complex problems lacking traditional solutions, fluctuating environments, and gaining insights from vast amounts of data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of Applications\n",
    "\n",
    "Examples of various machine learning tasks and the corresponding techniques used to tackle them. Here's a summary:\n",
    "\n",
    "- Image classification: Analyzing images of products on a production line can be performed using convolutional neural networks (CNNs).\n",
    "\n",
    "- Semantic segmentation: Detecting tumors in brain scans involves classifying each pixel in the image to determine the location and shape of tumors, typically using CNNs.\n",
    "\n",
    "- Text classification: Automatically classifying news articles or flagging offensive comments on discussion forums can be done using recurrent neural networks (RNNs), CNNs, or Transformers.\n",
    "\n",
    "- Text summarization: Automatically summarizing long documents falls under the branch of natural language processing (NLP) known as text summarization, using similar tools as text classification.\n",
    "\n",
    "- Chatbot or personal assistant: Creating a chatbot or personal assistant involves multiple NLP components, including natural language understanding (NLU) and question-answering modules.\n",
    "\n",
    "- Revenue forecasting: Predicting a company's revenue based on performance metrics is a regression task and can be tackled using various regression models or artificial neural networks. Sequential information can be incorporated using RNNs, CNNs, or Transformers.\n",
    "\n",
    "- Speech recognition: Making an app react to voice commands requires processing audio samples, typically using RNNs, CNNs, or Transformers.\n",
    "\n",
    "- Anomaly detection: Detecting credit card fraud involves anomaly detection techniques.\n",
    "\n",
    "- Clustering: Segmenting clients based on their purchases for targeted marketing strategies is achieved through clustering techniques.\n",
    "\n",
    "- Data visualization: Representing complex, high-dimensional datasets in a clear and insightful diagram often involves dimensionality reduction techniques.\n",
    "\n",
    "- Recommender systems: Recommending products based on past purchases can be accomplished by feeding data into an artificial neural network trained on past sequences of purchases across all clients.\n",
    "\n",
    "- Intelligent game bot: Building intelligent bots for games often involves using reinforcement learning (RL) techniques, where agents are trained to maximize rewards over time within a given environment.\n",
    "\n",
    "Machine Learning tasks are vast and complex, requiring a variety of techniques to address different challenges, highlighting the breadth and depth of Machine Learning applications.\n",
    "Overall, these examples demonstrate the wide range of tasks that Machine Learning can handle and the diverse techniques employed to solve them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of Machine Learning Systems\n",
    "\n",
    "Machine Learning systems can be classified into different types based on various criteria. Here are the major categories:\n",
    "\n",
    "## Supervised Learning\n",
    "\n",
    "In supervised learning, the training set includes labeled data, where the desired solutions are provided. It is commonly used for classification tasks, such as spam filtering, and regression tasks, such as predicting car prices.\n",
    "\n",
    "Examples of supervised learning algorithms:\n",
    "- k-Nearest Neighbors\n",
    "- Linear Regression\n",
    "- Logistic Regression\n",
    "- Support Vector Machines (SVMs)\n",
    "- Decision Trees and Random Forests\n",
    "- Neural networks\n",
    "\n",
    "## Unsupervised Learning\n",
    "\n",
    "In unsupervised learning, the training data is unlabeled. The system learns to find patterns and relationships within the data.\n",
    "\n",
    "Examples of unsupervised learning algorithms:\n",
    "- Clustering (e.g., K-Means, DBSCAN, Hierarchical Cluster Analysis)\n",
    "- Anomaly detection and novelty detection (e.g., One-class SVM, Isolation Forest)\n",
    "- Visualization and dimensionality reduction (e.g., Principal Component Analysis, t-SNE)\n",
    "- Association rule learning (e.g., Apriori, Eclat)\n",
    "\n",
    "## Semisupervised Learning\n",
    "\n",
    "Semisupervised learning involves partially labeled data. Some algorithms can utilize both labeled and unlabeled data for training.\n",
    "\n",
    "## Reinforcement Learning\n",
    "\n",
    "Reinforcement learning systems learn by interacting with an environment, receiving rewards or penalties based on their actions. They learn the best strategies or policies to maximize long-term rewards.\n",
    "\n",
    "## Batch Learning\n",
    "\n",
    "In batch learning, the system is trained using all available data, and the learning process is performed offline. It requires substantial time and resources to train the system, and updating it requires retraining on the full dataset.\n",
    "\n",
    "## Online Learning\n",
    "\n",
    "In online learning, the system learns incrementally by sequentially processing data instances as they arrive. It is suitable for systems that receive continuous data flow and need to adapt to changes rapidly. Online learning is also useful for handling huge datasets that cannot fit into memory.\n",
    "\n",
    "These categories are not exclusive and can be combined. For example, a state-of-the-art spam filter can be an online, model-based, supervised learning system.\n",
    "\n",
    "Note: The text provided contains additional details and examples for each category, which are not included in this summary.\n",
    "\n",
    "---\n",
    "\n",
    "# Instance-Based Versus Model-Based Learning\n",
    "\n",
    "Instance-based learning compares new data points to known data points and uses them directly for predictions, assuming similar instances have similar outcomes (e.g., k-Nearest Neighbors, Case-Based Reasoning).\n",
    "\n",
    "Model-based learning detects patterns in training data and builds a predictive model (e.g., Linear Regression, Logistic Regression, Support Vector Machines, Decision Trees, Neural Networks).\n",
    "\n",
    "Instance-based learning is useful for complex data distributions and non-linear decision boundaries, adapting well to data changes but can be computationally expensive for large datasets.\n",
    "\n",
    "Model-based learning creates compact representations, enabling faster inference and robust handling of noisy data, but may struggle with sparse data or complex relationships between features.\n",
    "\n",
    "The choice between approaches depends on the problem, data, resources, and desired trade-offs between accuracy and efficiency.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FROM BOOK: To be updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and prepare the data\n",
    "data_root = \"https://github.com/ageron/data/raw/main/\"\n",
    "lifesat = pd.read_csv(data_root + \"lifesat/lifesat.csv\")\n",
    "X = lifesat[[\"GDP per capita (USD)\"]].values\n",
    "y = lifesat[[\"Life satisfaction\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>GDP per capita (USD)</th>\n",
       "      <th>Life satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Russia</td>\n",
       "      <td>26456.387938</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Greece</td>\n",
       "      <td>27287.083401</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>28384.987785</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Latvia</td>\n",
       "      <td>29932.493910</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hungary</td>\n",
       "      <td>31007.768407</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country  GDP per capita (USD)  Life satisfaction\n",
       "0   Russia          26456.387938                5.8\n",
       "1   Greece          27287.083401                5.4\n",
       "2   Turkey          28384.987785                5.5\n",
       "3   Latvia          29932.493910                5.9\n",
       "4  Hungary          31007.768407                5.6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overview of the data\n",
    "lifesat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the data\n",
    "lifesat.plot(kind='scatter', grid=True,\n",
    "             x=\"GDP per capita (USD)\", y=\"Life satisfaction\")\n",
    "plt.axis([23_500, 62_500, 4, 9])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a linear model\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.30165767]]\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction for Cyprus\n",
    "X_new = [[37_655.2]]  # Cyprus' GDP per capita in 2020\n",
    "print(model.predict(X_new)) # outputs [[6.30165767]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary:\n",
    "\n",
    "- You studied the data.\n",
    "\n",
    "- You selected a model.\n",
    "\n",
    "- You trained it on the training data (i.e., the learning algorithm\n",
    "searched for the model parameter values that minimize a cost\n",
    "function).\n",
    "\n",
    "- Finally, you applied the model to make predictions on new cases\n",
    "(this is called inference), hoping that this model will generalize\n",
    "well."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "additional content from https://github.com/ageron/handson-ml3/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Challenges of Machine Learning\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, this text discusses the potential issues that can arise in machine learning due to:\n",
    "- bad data\n",
    "- and bad algorithms.\n",
    "Here are the key points covered:\n",
    "\n",
    "### Bad Data:\n",
    "\n",
    "- Insufficient Quantity of Training Data: Machine learning algorithms generally require a large amount of data to perform well.\n",
    "- Nonrepresentative Training Data: The training data should be representative of the cases the model needs to generalize to.\n",
    "- Poor-Quality Data: Errors, outliers, and noise in the training data can hinder the model's ability to detect underlying patterns.\n",
    "- Irrelevant Features: The training data should contain relevant features and avoid irrelevant ones for effective learning.\n",
    "\n",
    "### Bad Algorithms:\n",
    "\n",
    "- Overfitting the Training Data: Overfitting occurs when a model performs well on the training data but fails to generalize to new instances.\n",
    "- Underfitting the Training Data: Underfitting happens when a model is too simple to capture the underlying structure of the data.\n",
    "\n",
    "### Stepping Back:\n",
    "\n",
    "- Machine Learning is about improving machine performance through learning from data instead of explicit rule-based programming.\n",
    "- Different types of ML systems exist, such as supervised/unsupervised, batch/online, and instance-based/model-based.\n",
    "- The quality of the training data, appropriate feature selection, and model complexity are crucial for successful ML outcomes.\n",
    "\n",
    "### Additional notes:\n",
    "\n",
    "- The importance of data quantity and quality is emphasized, often outweighing algorithm choice for complex problems.\n",
    "- Examples of sampling bias in historical polls and YouTube search results are provided.\n",
    "- Cleaning up training data and performing feature engineering are vital tasks for data scientists.\n",
    "- Overfitting can be addressed by simplifying the model, gathering more data, or reducing noise.\n",
    "- Underfitting can be resolved by using more powerful models, improving feature selection, or relaxing model constraints.\n",
    "- Evaluation and fine-tuning of trained models are essential for assessing their generalization performance.\n",
    "\n",
    "Overall, the text highlights the significance of data quality, algorithm selection, and model complexity in machine learning tasks, emphasizing the iterative nature of model development and evaluation.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and Validating"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To assess how well a model will generalize to new cases, it is crucial to evaluate its performance on unseen data.\n",
    "- The common approach is to split the data into training and test sets, using the test set to estimate the model's generalization error.\n",
    "- If the training error is low but the generalization error is high, it indicates overfitting, where the model memorizes the training data instead of learning patterns.\n",
    "- It is recommended to allocate around 80% of the data for training and hold out 20% for testing, ensuring an adequate sample size for reliable estimates.\n",
    "\n",
    "\n",
    "### Hyperparameter Tuning and Model Selection\n",
    "\n",
    "- When choosing between different models or adjusting hyperparameters, evaluating their performance on a test set is essential.\n",
    "- However, evaluating multiple models on the test set and selecting the best one can lead to overfitting to the test set.\n",
    "- Holdout validation offers a solution by creating a separate validation set from the training data to compare and select models.\n",
    "- After selecting the best model through holdout validation, training it on the full training set provides the final model for evaluation on the test set.\n",
    "\n",
    "\n",
    "### Data Mismatch\n",
    "\n",
    "- In cases where training data is abundant but may not represent the actual production data, issues of data mismatch can arise.\n",
    "- To address this, the validation and test sets should be composed exclusively of representative data expected in production.\n",
    "- The train-dev set can be introduced, holding out some training data for further evaluation of the model's performance.\n",
    "- If the model performs poorly on the validation set but well on the train-dev set, data mismatch is likely the cause, requiring preprocessing or data adjustments.\n",
    "\n",
    "\n",
    "### No Free Lunch Theorem\n",
    "\n",
    "- A model simplifies observations by making assumptions and discarding irrelevant details.\n",
    "- The No Free Lunch (NFL) theorem states that without assumptions about the data, no model is inherently superior.\n",
    "- To identify the best model, evaluations must be conducted on reasonable assumptions and a limited set of models.\n",
    "- For simple tasks, linear models with varying regularization levels may suffice, while complex problems may require evaluation of various neural networks.\n",
    "\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "- Testing and validating machine learning models are crucial steps to ensure their generalization performance.\n",
    "- Splitting data into training and test sets allows estimation of the model's generalization error.\n",
    "- Holdout validation helps in model selection and hyperparameter tuning, mitigating overfitting to the test set.\n",
    "- Data mismatch can be addressed by representative validation and test sets, with the train-dev set assisting in identifying the cause of performance issues.\n",
    "- Considering the No Free Lunch theorem, making reasonable assumptions and evaluating a limited set of models can guide the selection process.\n",
    "- By following these best practices, AI practitioners can improve the reliability and performance of their machine learning models.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How would you define Machine Learning?\n",
    "\n",
    "   Machine Learning is a field of study that involves developing algorithms and models capable of learning patterns and making predictions or decisions from data, without being explicitly programmed. It focuses on enabling computers to learn and improve from experience, allowing them to perform tasks and make accurate predictions in complex and uncertain environments.\n",
    "\n",
    "2. Can you name four types of problems where it shines?\n",
    "\n",
    "   Four types of problems where Machine Learning shines are:\n",
    "   - Image and speech recognition: Machine Learning algorithms excel at detecting patterns and extracting meaningful information from images and audio data.\n",
    "   - Natural Language Processing (NLP): Machine Learning is widely used in language translation, sentiment analysis, chatbots, and text summarization.\n",
    "   - Recommendation systems: Machine Learning algorithms are effective in recommending personalized products, movies, music, or content based on user preferences and historical data.\n",
    "   - Anomaly detection: Machine Learning can identify unusual patterns or outliers in data, making it valuable for fraud detection, network intrusion detection, or identifying manufacturing defects.\n",
    "\n",
    "3. What is a labeled training set?\n",
    "\n",
    "   A labeled training set refers to a dataset used in supervised learning, where each example or instance is associated with a corresponding label or target value. The labels represent the desired output or prediction for the given input. It serves as the basis for training a Machine Learning model to learn the relationship between the input features and their corresponding labels, enabling the model to make predictions on unseen data.\n",
    "\n",
    "4. What are the two most common supervised tasks?\n",
    "\n",
    "   The two most common supervised tasks in Machine Learning are:\n",
    "   - Classification: In classification, the goal is to predict the discrete class or category of a given input instance. The model learns from labeled training data to classify new instances into predefined classes or categories.\n",
    "   - Regression: In regression, the objective is to predict a continuous numerical value or quantity based on input features. The model learns from labeled training data to estimate a target value within a range of possible values.\n",
    "\n",
    "5. Can you name four common unsupervised tasks?\n",
    "\n",
    "   Four common unsupervised tasks in Machine Learning include:\n",
    "   - Clustering: Clustering aims to group similar instances together based on their intrinsic characteristics or similarities. It helps in discovering underlying patterns or structures in the data without any predefined labels.\n",
    "   - Dimensionality Reduction: Dimensionality reduction techniques reduce the number of input features while preserving important information. It helps in visualizing high-dimensional data, removing noise, and improving computational efficiency.\n",
    "   - Anomaly Detection: Anomaly detection focuses on identifying rare or abnormal instances in a dataset that deviate significantly from the expected patterns. It is useful in fraud detection, network intrusion detection, or identifying unusual events.\n",
    "   - Association Rule Learning: Association rule learning discovers interesting relationships or associations among variables in a dataset. It is often used in market basket analysis or recommendation systems to identify frequent itemsets or item co-occurrences.\n",
    "\n",
    "6. What type of Machine Learning algorithm would you use to allow a robot to walk in various unknown terrains?\n",
    "\n",
    "   Reinforcement Learning would be an appropriate type of Machine Learning algorithm for enabling a robot to walk in various unknown terrains. Reinforcement Learning involves training an agent to learn optimal actions in an environment by receiving feedback in the form of rewards or penalties. The robot could explore different actions and learn from the consequences, gradually improving its walking strategy to navigate unfamiliar terrains effectively.\n",
    "\n",
    "7. What type of algorithm would you use to segment your customers into multiple groups?\n",
    "\n",
    "   To segment customers into multiple groups, a common algorithm used is Cluster Analysis, specifically a technique called K-means clustering. K-means clustering is an unsupervised learning algorithm that partitions the data into distinct clusters based on similarity. It assigns each customer to a cluster based on their shared characteristics or behavior, allowing businesses to target different customer segments with tailored marketing strategies.\n",
    "\n",
    "8. Would you frame the problem of spam detection as a supervised learning problem or an unsupervised learning problem?\n",
    "\n",
    "   The problem of spam detection is typically framed as a supervised learning problem. In supervised learning, the model learns from labeled examples where each email is labeled as spam or not spam. The model then generalizes from the labeled data to classify new, unseen emails as spam or not spam. The availability of labeled training data allows the model to learn the patterns and characteristics of spam emails and make accurate predictions.\n",
    "\n",
    "9. What is an online learning system?\n",
    "\n",
    "   An online learning system, also known as incremental learning, refers to a Machine Learning approach where the model continuously learns and adapts to new data instances in real-time or in a sequential manner. In online learning, the model is updated incrementally with each new observation, incorporating new knowledge while preserving information from previous training examples. It is especially useful in scenarios where data arrives in a streaming fashion or when the underlying data distribution evolves over time.\n",
    "\n",
    "10. What is out-of-core learning?\n",
    "\n",
    "    Out-of-core learning, or online-out-of-core learning, is a technique used when the dataset is too large to fit into the computer's memory. In such cases, the data is processed in smaller \"chunks\" or batches that can fit in memory. The learning algorithm iterates over these chunks, updating the model's parameters incrementally. Out-of-core learning enables training on massive datasets that exceed the memory capacity of the machine, allowing for scalable and efficient learning.\n",
    "\n",
    "11. What type of learning algorithm relies on a similarity measure to make predictions?\n",
    "\n",
    "    Instance-based learning algorithms, such as k-nearest neighbors (KNN), rely on a similarity measure to make predictions. These algorithms classify or regress new instances based on their similarity to the instances in the training set. The similarity measure, often based on distance metrics, determines the closest neighbors to a given instance and assigns predictions based on the labels or values of those neighbors.\n",
    "\n",
    "12. What is the difference between a model parameter and a learning algorithm’s hyperparameter?\n",
    "\n",
    "    A model parameter is a configuration or setting that is learned from the training data by the learning algorithm. Model parameters define the internal representation and behavior of the trained model. For example, in linear regression, the coefficients or weights assigned to each feature are model parameters.\n",
    "\n",
    "    On the other hand, a learning algorithm's hyperparameter is a setting that is not directly learned from the data but determined by the practitioner before the learning process begins. Hyperparameters influence the learning algorithm's behavior and control aspects such as model complexity, regularization, or learning rate. Examples of hyperparameters include the number of hidden layers in a neural network or the penalty parameter in a support vector machine (SVM).\n",
    "\n",
    "13. What do model-based learning algorithms search for? What is the most common strategy they use to succeed? How do they make predictions?\n",
    "\n",
    "    Model-based learning algorithms search for an optimal model that best fits the training data and generalizes well to unseen data. The most common strategy used by these algorithms is to define an objective function or a cost function that quantifies how well the model fits the data. The algorithms then aim to minimize this objective function by adjusting the model's parameters or hyperparameters through optimization techniques.\n",
    "\n",
    "    Once trained, model-based learning algorithms make predictions by applying the learned model to new, unseen instances. They use the relationships and patterns learned from the training data to map input features to output predictions or decisions. The specific prediction mechanism varies depending on the algorithm and task at hand, ranging from simple mathematical formulas (e.g., linear regression) to complex decision boundaries (e.g., neural networks).\n",
    "\n",
    "14. Can you name four of the main challenges in Machine Learning?\n",
    "\n",
    "    Four main challenges in Machine Learning are:\n",
    "\n",
    "    1. Overfitting: Overfitting occurs when a model performs well on the training data but fails to generalize to new, unseen data. It happens when the model becomes too complex or when the training data is insufficient or noisy.\n",
    "\n",
    "    2. Data quality and quantity: Machine Learning heavily relies on the availability of high-quality, representative data. Limited or biased data can hinder model performance and introduce biases and inaccuracies.\n",
    "\n",
    "    3. Feature selection and engineering: Selecting relevant features or engineering informative representations from raw data is crucial for model effectiveness. Choosing the right set of features or designing effective feature extraction methods can be challenging.\n",
    "\n",
    "    4. Computational complexity: Training complex models or processing large datasets can be computationally demanding. Balancing model complexity with computational resources is an ongoing challenge in Machine Learning.\n",
    "\n",
    "15. If your model performs great on the training data but generalizes poorly to new instances, what is happening? Can you name three possible solutions?\n",
    "\n",
    "    If a model performs well on the training data but generalizes poorly to new instances, it is likely suffering from overfitting. Overfitting occurs when the model has learned the specific patterns and noise in the training data, making it less capable of capturing the underlying general patterns present in unseen data.\n",
    "\n",
    "    Three possible solutions to address overfitting are:\n",
    "\n",
    "    1. Regularization: Applying regularization techniques, such as L1 or L2 regularization, helps to prevent overfitting by adding a penalty term to the objective function. This discourages the model from fitting the noise in the training data and encourages more generalizable patterns.\n",
    "\n",
    "    2. Cross-validation: Using cross-validation techniques, such as k-fold cross-validation, allows for a more robust assessment of the model's performance. It helps to evaluate the model on multiple validation sets and detect overfitting tendencies.\n",
    "\n",
    "    3. Increasing training data: Providing more diverse and representative training data can reduce overfitting. With more examples, the model can learn more generalizable patterns and be less prone to memorizing specific instances.\n",
    "\n",
    "16. What is a test set, and why would you want to use it?\n",
    "\n",
    "    A test set is a subset of data that is held out from the model training process and used to evaluate the final performance of the trained model. It consists of examples that the model has never seen during training, simulating real-world scenarios where the model encounters new instances. By evaluating the model on the test set, practitioners can estimate the model's generalization ability and assess its performance in making predictions or decisions on unseen data.\n",
    "\n",
    "17. What is the purpose of a validation set?\n",
    "\n",
    "    The purpose of a validation set is to assess the performance of the model during the training process and assist in hyperparameter tuning and model selection. Unlike the test set, which is used only at the end to evaluate the final model, the validation set is used iteratively during training. By evaluating the model's performance on the validation set, practitioners can make informed decisions about adjusting hyperparameters, selecting the best model, or early stopping if the model starts to overfit.\n",
    "\n",
    "18. What is the train-dev set, when do you need it, and how do you use it?\n",
    "\n",
    "    The train-dev set, short for training-development set, is a subset of the training data that is held out for further evaluation and analysis. It is created by splitting a portion of the training data aside, usually when the training set is large enough.\n",
    "\n",
    "    The train-dev set is useful when the model performs well on the training set but poorly on the validation set. If the model shows a significant difference in performance between the training set and validation set, it indicates a potential issue of data mismatch or other sources of performance degradation.\n",
    "\n",
    "    By evaluating the model's performance on the train-dev set, practitioners can diagnose and investigate the cause of the performance discrepancy. It helps identify whether the model is overfitting to specific patterns in the training data or if there are other underlying issues that need to be addressed.\n",
    "\n",
    "19. What can you do if your model performs well on the training set but poorly on the dev set (or validation set)?\n",
    "\n",
    "    If a model performs well on the training set but poorly on the dev set or validation set, it suggests that the model is overfitting to the training data and fails to generalize to new instances. Several steps can be taken to address this issue:\n",
    "\n",
    "    1. Increase the size of the training set: Providing more diverse and representative training examples can help the model learn more generalizable patterns and reduce overfitting tendencies.\n",
    "\n",
    "    2. Apply regularization techniques: Regularization methods, such as L1 or L2 regularization, can be applied to penalize overly complex models and discourage fitting to noise in the training data.\n",
    "\n",
    "    3. Adjust model complexity: Simplifying the model architecture or reducing the number of parameters can help prevent overfitting. This can involve reducing the number of layers or nodes in a neural network or decreasing the degree of a polynomial model.\n",
    "\n",
    "    4. Feature engineering and selection: Reevaluating the features used by the model and performing feature engineering or selection can help improve generalization. Removing irrelevant or redundant features and adding more informative ones can lead to better performance on unseen data.\n",
    "\n",
    "    5. Cross-validation and hyperparameter tuning: Using techniques like k-fold cross-validation, practitioners can assess the model's performance on multiple validation sets and fine-tune hyperparameters to find the optimal configuration that balances underfitting and overfitting.\n",
    "\n",
    "    6. Collect more diverse data: Gathering additional data that covers a broader range of scenarios or edge cases can help the model generalize better. This can involve collecting new examples, synthesizing additional instances, or using data augmentation techniques.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
