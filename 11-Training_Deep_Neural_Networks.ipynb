{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 11. Training Deep Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Chapter 10, the concept of artificial neural networks was introduced, but the focus was on shallow networks with only a few hidden layers. However, for tackling complex tasks like detecting numerous objects in high-resolution images, deeper neural networks with many layers and connections are required, presenting several challenges. These challenges include the vanishing and exploding gradients problem, insufficient training data, slow training, and the risk of overfitting in models with millions of parameters. \n",
    "\n",
    "The chapter discusses solutions to these issues, including techniques for addressing gradient problems, transfer learning, unsupervised pretraining, optimization methods, and regularization techniques, enabling the training of very deep neural networks in the field of deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Vanishing/Exploding Gradients Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
